{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# LinkedIn Data Cleaning Notebook\n",
    "\n",
    "## Objective:\n",
    "- Read files and convert xlsx into csv files\n",
    "- Read LinkedIn CSV files and extract connections.\n",
    "- Create a cleaned adjacency list (graph representation).\n",
    "- Given Summary of graph using First Year Batch List- AllSU.csv\n",
    "- Save the cleaned data as a JSON file.\n",
    "- Log skipped rows for debugging.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Manual Work\n",
    "- Some students submitted their CSV files with file names that do not match their LinkedIn profile names so manual       cleaning of file names was needed to ensure accurate mapping with LinkedIn profiles.\n",
    "- Extracted one zip file.\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Imports\n",
    "import os\n",
    "import csv\n",
    "import json\n",
    "from collections import defaultdict\n",
    "import pandas as pd\n",
    "import difflib\n",
    "import shutil"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Reads .csv and .xlsx files from a folder.\n",
    "\n",
    "- Converts .xlsx files into .csv.\n",
    "\n",
    "- Matches each file with student names using fuzzy matching.\n",
    "\n",
    "- Renames and copies them to a clean output folder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Swati_Kumari - Swati kumari.csv → Swati kumari.csv\n",
      "Anand Kumar_Pandey - Anand Kumar Pandey.csv → Anand Kumar Pandey.csv\n",
      "YuvrajSingh_Bhati - Yuvraj Bhati.csv → Yuvraj Singh Bhati.csv\n",
      "Harisingh_Rajpoot - Harisingh Rajpoot.csv → Harisingh Rajpoot.csv\n",
      "Divyanshi_Rathour - Divyanshi Rathour.csv → Divyanshi Rathour.csv\n",
      "Aradhya_Patel - Aradhya Patel.csv → Aradhya Patel.csv\n",
      "Abhishek_Singh - Abhishek Singh.csv → Abhishek Singh.csv\n",
      "Mausam_kumari - Mausam kumari.csv → Mausam kumari.csv\n",
      "Ashwin_Yadav - Ashwin Yadav.csv → Ashwin Yadav.csv\n",
      "Anuradha_Tiwari - Anuradha Tiwari.csv → Anuradha Tiwari.csv\n",
      "Shubham_Kang - Shubham Kang.csv → Shubham Kang.csv\n",
      "Rahul_Kumar - Rahul Kumar.csv → Rahul Kumar.csv\n",
      "Priyadarshi_Kumar - Priyadarshi Kumar.csv → Priyadarshi Kumar.csv\n",
      "Shivang_Dubey - Shivang Dubey.csv → Shivang Dubey.csv\n",
      "Sarthaksuman_Mishra - Sarthak Mishra.csv → SarthakSuman Mishra.csv\n",
      "Lakhan_Rathore - Lakhan Rathore.csv → Lakhan Rathore.csv\n",
      "Dilip_Suthar - DILIP SUTHAR.csv → Dilip Suthar.csv\n",
      "ByagariPraveen_Kumar - Byagari Kumar.csv → Byagari Praveen Kumar.csv\n",
      "Nirmal Mewada - NIRMAL MEWADA.csv → Nirmal Mewada.csv\n",
      "Vinay_Kumar - VINAY KUMAR.csv → Vinay Kumar.csv\n",
      "Connections - RAVI RAJPUT.csv → Ravi Rajput.csv\n",
      "Anshu_Kumar - Anshu Kumar.csv → Anshu Kumar.csv\n",
      "Ranjeet_Yadav - Ranjeet Yadav.csv → Ranjeet Yadav.csv\n",
      "Gaurav_Rathore - Gaurav Rathore.csv → Gaurav Rathore.csv\n",
      "JAMAL_AKHTAR - JAMAL AKHTAR.csv → Jamal Akhtar.csv\n",
      "Himanshu_kumar - Himanshu Kumar.csv → Himanshu Kumar.csv\n",
      "Mehtab_Alam - MEHTAB ALAM.csv → Mehtab Alam.csv\n",
      "Yuvraj_Chirag - Yuvraj Chirag.csv → Yuvraj Chirag.csv\n",
      "Arjun Kadam - Arjun Kadam.csv → Arjun Kadam.csv\n",
      "Ajit_Yadav - Ajit Yadav.csv → Ajit Yadav.csv\n",
      "Gaurav_Tiwari - GAURAV TIWARI.csv → Gaurav Tiwari.csv\n",
      "Pawan_Kushwah - Pawan Kushwah.csv → Pawan Kushwah.csv\n",
      "Ritik_Singh - ritik singh.csv → Ritik Singh.csv\n",
      "Bhagwati_Chouhan - Bhagwati NO-LASTNAME.csv → Bhagwati Chouhan.csv\n",
      "Bhaskar_mahato - Bhaskar Mahato.csv → Bhaskar Mahato.csv\n",
      "Anamika_Kumari - Anamika Kumari.csv → Anamika Kumari.csv\n",
      "Disha_Sahu - Disha Sahu.csv → Disha Sahu.csv\n",
      "Janu_Chaudhary - Janu Chaudhary.csv → Janu Chaudhary.csv\n",
      "Manish_Tiwari - MANISH  TIWARI.csv → Manish Tiwari.csv\n",
      "Prachi_Dhakad - PRACHI DHAKAD.csv → Prachi Dhakad.csv\n",
      "Pooran_Singh - POORAN SINGH.csv → Pooran Singh.csv\n",
      "Connections - Anand Singh.csv → Anand Singh.csv\n",
      "Pinky_Rana - Pinky Rana.csv → Pinky Rana.csv\n",
      "Maneesh_Sakhwar - Maneesh Sakhwar.csv → Maneesh Sakhwar.csv\n",
      "Rani_Kumari - Rani Kumari.csv → Rani Kumari.csv\n",
      "Rajiv_Kumar - RAJIV KUMAR.csv → Rajiv Kumar.csv\n",
      "Akanksha_Kushwaha - Akanksha.csv → Akanksha Kushwaha.csv\n",
      "Uppara Sai_Maithreyi - UPPARA MAITHREYI.csv → Uppara Sai Maithreyi.csv\n",
      "Arpita_Tripathi - Arpita Tripathi.csv → Arpita Tripathi.csv\n",
      "Sauhard_kumar - Sauhard kumar.csv → Sauhard Kumar.csv\n",
      "Himanshu_Srivastav - Himanshu Srivastav.csv → Himanshu Srivastav.csv\n",
      "Connections - Aman Verma.csv → Aman Verma.csv\n",
      "Anushri_Mishra - Anushri Mishra.csv → Anushri Mishra.csv\n",
      "Ayush_Kumar - Ayush Kumar.csv → Ayush Kumar.csv\n",
      "Naman_Damami - Naman Damami.csv → Naman Damami.csv\n",
      "Ishant_Bhoyar - ISHANT BHOYAR.csv → Ishant Laxman Bhoyar.csv\n",
      "KARANPAL_SINGH_RANAWAT - KARANPAL SINGH RANAWAT.csv → Karanpal Singh Ranawat.csv\n",
      "Samina_Sultana.csv → Samina Sultana.csv\n",
      "CHANDAN_GIRI - Chandan Giri.csv → Chandan Giri.csv\n",
      "Connections - Ompal Yadav.csv → Ompal Yadav.csv\n",
      "Shubham Kumar - Shubham Kumar.csv → Shubham Kumar.csv\n",
      "Monu_Rajpoot - Monu Rajpoot.csv → Monu Rajpoot.csv\n",
      "Ujjval_Baijal - Ujjval Baijal.csv → Ujjval Baijal.csv\n",
      "Pragati_Chauhan - Pragati Chauhan.csv → Pragati Chauhan.csv\n",
      "Prem kumar.csv → Prem Kumar.csv\n",
      "Rohit_Malviya - Rohit Malviya.csv → Rohit Malviya.csv\n",
      "connections - N. Arun Kumar.csv → N. Arun Kumar.csv\n",
      "Vinay_Gupta - VINAY GUPTA.csv → Vinay Gupta.csv\n",
      "khushi_narwariya - Khushi Narwariya.csv → Khushi Narwariya.csv\n",
      "Sandeep_kumar - Sandeep Kumar.csv → Sandeep Kumar.csv\n",
      "Sandhya_Kaushal - Sandhya Kaushal.csv → Sandhya Kaushal.csv\n",
      "Sajan_Kumar - SAJAN KUMAR.csv → Sajan Kumar.csv\n",
      "Hiranya_Patil - Hiranya Patil.csv → Hiranya Patil.csv\n",
      "HimanshuKanwarChundawat - Himanshu Chundawat.csv → Himanshu Kanwar Chundawat.csv\n",
      "Mohit_Sharma - Mohit Sharma.csv → Mohit Sharma.csv\n",
      "connection1-1 - Aman Adarsh.csv → Aman Adarsh.csv\n",
      "Ramraj_Nagar - Ramraj Nagar.csv → Ramraj Nagar.csv\n",
      "Saurabh_Bisht - Saurabh Bisht.csv → Saurabh Bisht.csv\n",
      "Connections - Harshit Chaturvedi.csv → Harshit Chaturvedi.csv\n",
      "Arun_Singh.csv → Arun Singh.csv\n",
      "Sunny_Kumar - Sunny Kumar.csv → Sunny Kumar.csv\n",
      "Sandhya_Parmar - Sandhya Parmar.csv → Sandhya Parmar.csv\n",
      "Vivek_Singh - Vivek Kumar.csv → Vivek Singh.csv\n",
      "Sneha_Shaw.csv → Sneha Shaw.csv\n",
      "Rohit_kumar - ROHIT KUMAR.csv → Rohit Kumar.csv\n",
      "Vivek_kumar - VIVEK KUMAR.csv → Vivek Kumar.csv\n",
      "Manoj_Dewda - Manoj Dewda.csv → Manoj Dewda.csv\n",
      "Debangsu_Misra - Debangsu Misra.csv → Debangsu Misra.csv\n",
      "Ajay_Jatav  - Ajay Jatav.csv → Ajay Jatav.csv\n",
      "Neeraj_Parmar - NEERAJ PARMAR.csv → Neeraj Parmar.csv\n",
      "Suyash_Yadav - Suyash Yadav.csv → Suyash Yadav.csv\n",
      "Ayush_yadav - AYUSH YADAV.csv → Ayush Yadav.csv\n",
      "Prerana_Rajnag - PRERANA RAJNAG.csv → Prerana Rajnag.csv\n",
      "Priya_saini - Priya Saini.csv → Priya Saini.csv\n",
      "Ekta Kumari - Ekta Kumari.csv → Ekta Kumari.csv\n",
      "amit_kumar - Amit Kumar.csv → Amit Kumar.csv\n",
      "Shivam_Shukla.csv → Shivam Shukla.csv\n",
      "Prabhat_Patidar - prabhat patidar.csv → Prabhat Patidar.csv\n",
      "Shlok_Gupta - Shlok Gupta.csv → Shlok Gupta.csv\n",
      "Alok_raj - Alok Raj.csv → Alok Raj.csv\n",
      "Pranjal_Dubey - Pranjal Dubey.csv → Pranjal Dubey.csv\n",
      "Satish_Mahto - Satish Mahto.csv → Satish Mahto.csv\n",
      "Connection - VISHAL KUMAR.csv → Vishal Kumar.csv\n",
      "Aaditya_Raj - Aaditya Raj.csv → Aaditya Raj.csv\n",
      "Shilpi_Shaw - Shilpi Shaw.csv → Shilpi Shaw.csv\n",
      "aryan_saini - Aryan Saini.csv → Aryan Saini.csv\n",
      "Shahid_Ansari - Shahid Ansari.csv → Shahid Ansari.csv\n",
      "Divyanshi_Sahu - Divyanshi Sahu.csv → Divyanshi Sahu.csv\n",
      "linkedin list - Nidhi Kumari.csv → Nidhi Kumari.csv\n",
      "gaurav_khainwar.csv - Gaurav Khainwar.csv → Gaurav Khainwar.csv\n",
      "Aditya_Singh - Aditya Singh.csv → Aditya Singh.csv\n",
      "Mohd_Monis - Monis.csv → Mohd Monis.csv\n",
      "Pushpraj_Singh - Pushpraj Singh.csv → Pushpraj Singh.csv\n",
      "Mayank_Raj - Mayank Raj.csv → Mayank Raj.csv\n",
      "Nikhil_Chaurasiya - Nikhil Chaurasiya.csv → Nikhil Chaurasiya.csv\n",
      "Aman_ Adarsh.csv → Aman Adarsh.csv\n",
      "Manoj_Dewda - Manoj Dewda.csv → Manoj Dewda.csv\n",
      "Challa_Trivedh_Kumar - CHALLA TRIVEDH KUMAR.csv → Challa Trivedh Kumar.csv\n",
      "Kuldeep_Saraswat - Kuldeep saraswat.csv → Kuldeep saraswat.csv\n",
      "Ashwin_Yadav - Ashwin Yadav.csv → Ashwin Yadav.csv\n",
      "Afzal_Raza - Afzal Raza.csv → Mohammad Afzal Raza.csv\n",
      "Cleaned_Connections - Bhagwan Singh Rawat.csv → Bhagwan Singh Rawat.csv\n",
      "Chiranjeet_Biswas - Chiranjeet Biswas.csv → Chiranjeet Biswas.csv\n",
      "Rahul_Verma - Rahul Verma.csv → Rahul Verma.csv\n",
      "Aman_Singh - Aman Singh.csv → Aman Singh.csv\n",
      "Anoop_Kumar - ANOOP KUMAR.csv → ANOOP KUMAR.csv\n",
      "Ravi_Mourya - Ravi Mourya.csv → Ravi Mourya.csv\n",
      " MANOJ KHARKAR.csv → Manoj Moreshwar Kharkar.csv\n",
      "Yuvraj_Chirag - Yuvraj Chirag.csv → Yuvraj Chirag.csv\n",
      "Vishal_Bhardwaj - VISHAL BHARDWAJ.csv → Vishal Bhardwaj.csv\n",
      "\n",
      " All files matched successfully!\n",
      "\n",
      " Converted .xlsx files to CSV:\n",
      " - Ashwin_Yadav - Ashwin Yadav.csv\n",
      " - Manoj_Dewda - Manoj Dewda.csv\n",
      " - Yuvraj_Chirag - Yuvraj Chirag.csv\n",
      "\n",
      "The following files were skipped (not CSV/XLSX or hidden):\n",
      " - .DS_Store\n"
     ]
    }
   ],
   "source": [
    "# PATHS\n",
    "input_folder = \"LinkedIn Data Public\"\n",
    "student_csv = \"AllSU.csv\"\n",
    "output_folder = \"LinkedIn Data FILES\"\n",
    "os.makedirs(output_folder, exist_ok=True)\n",
    "\n",
    "#LOAD STUDENT NAMES \n",
    "student_df = pd.read_csv(student_csv)\n",
    "student_names = student_df['Full Name'].dropna().tolist()\n",
    "\n",
    "# CLEANING FUNCTION \n",
    "def clean_string(s):\n",
    "    s = s.replace(\"_\", \" \").strip().lower()\n",
    "    return ''.join(e for e in s if e.isalnum() or e == ' ')\n",
    "\n",
    "# TRACKERS\n",
    "unmatched_files = []\n",
    "skipped_files = []\n",
    "converted_files = []\n",
    "\n",
    "#RENAME FUNCTION\n",
    "def rename_files():\n",
    "    for file in os.listdir(input_folder):\n",
    "        file_path = os.path.join(input_folder, file)\n",
    "\n",
    "        # Skip hidden and invalid files\n",
    "        if file.startswith('.') or not (file.endswith('.csv') or file.endswith('.xlsx')):\n",
    "            skipped_files.append(file)\n",
    "            continue\n",
    "\n",
    "        #HANDLE .xlsx → .csv\n",
    "        if file.endswith(\".xlsx\"):\n",
    "            try:\n",
    "                df = pd.read_excel(file_path)\n",
    "                base_name = os.path.splitext(file)[0]\n",
    "                csv_path = os.path.join(input_folder, f\"{base_name}.csv\")\n",
    "                df.to_csv(csv_path, index=False)\n",
    "                file_path = csv_path\n",
    "                file = f\"{base_name}.csv\"\n",
    "                converted_files.append(file)\n",
    "            except Exception as e:\n",
    "                print(f\"Failed to convert {file} to CSV: {e}\")\n",
    "                skipped_files.append(file)\n",
    "                continue\n",
    "\n",
    "        base_name = os.path.splitext(file)[0]\n",
    "\n",
    "        # Fuzzy matching with student names\n",
    "        best_match = difflib.get_close_matches(\n",
    "            clean_string(base_name),\n",
    "            [clean_string(name) for name in student_names],\n",
    "            n=1,\n",
    "            cutoff=0.6\n",
    "        )\n",
    "\n",
    "        if best_match:\n",
    "            matched_name = next(\n",
    "                (name for name in student_names if clean_string(name) == best_match[0]), None\n",
    "            )\n",
    "            if matched_name:\n",
    "                new_filename = f\"{matched_name}.csv\"\n",
    "                new_path = os.path.join(output_folder, new_filename)\n",
    "                shutil.copy2(file_path, new_path)\n",
    "                print(f\"{file} → {new_filename}\")\n",
    "            else:\n",
    "                print(f\"⚠ Match logic failed for {file}\")\n",
    "                unmatched_files.append(file)\n",
    "        else:\n",
    "            print(f\"No close match for: {file}\")\n",
    "            unmatched_files.append(file)\n",
    "\n",
    "    # FINAL REPORT\n",
    "    if unmatched_files:\n",
    "        print(\"\\n The following files could not be matched to any student name:\")\n",
    "        for fname in unmatched_files:\n",
    "            print(f\" - {fname}\")\n",
    "    else:\n",
    "        print(\"\\n All files matched successfully!\")\n",
    "\n",
    "    if converted_files:\n",
    "        print(\"\\n Converted .xlsx files to CSV:\")\n",
    "        for fname in converted_files:\n",
    "            print(f\" - {fname}\")\n",
    "\n",
    "    if skipped_files:\n",
    "        print(\"\\nThe following files were skipped (not CSV/XLSX or hidden):\")\n",
    "        for fname in skipped_files:\n",
    "            print(f\" - {fname}\")\n",
    "\n",
    "# RUN\n",
    "rename_files()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Create a cleaned adjacency list (graph representation)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Normalize Names\n",
    "def normalize_name(name):\n",
    "    \"\"\"Convert name to lowercase and strip extra spaces to maintain consistency.\"\"\"\n",
    "    return \" \".join(name.strip().lower().split())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_valid_headers(file_path):\n",
    "    \"\"\"Finds a valid header row with 'First Name' and 'Last Name', ignoring case and hidden characters.\"\"\"\n",
    "    with open(file_path, newline='', encoding='utf-8-sig', errors='replace') as csvfile:\n",
    "        sample_reader = csv.reader(csvfile)\n",
    "        for i, row in enumerate(sample_reader):\n",
    "            # Normalize each column header\n",
    "            cleaned = [col.strip().lower().replace('\\u200b', '').replace('\\xa0', '') for col in row]\n",
    "            if \"first name\" in cleaned and \"last name\" in cleaned:\n",
    "                return row  # Return original for DictReader\n",
    "            if i >= 4:\n",
    "                break\n",
    "    return None\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "#  Create Adjacency List\n",
    "def create_adjacency_list(folder_path):\n",
    "    adjacency_list = defaultdict(set)\n",
    "    skipped_rows_log = []\n",
    "    csv_files = {normalize_name(os.path.splitext(f)[0]) for f in os.listdir(folder_path) if f.endswith(\".csv\")}\n",
    "\n",
    "    for filename in os.listdir(folder_path):\n",
    "        if not filename.endswith(\".csv\"):\n",
    "            continue\n",
    "\n",
    "        file_path = os.path.join(folder_path, filename)\n",
    "        person_name = normalize_name(os.path.splitext(filename)[0])\n",
    "        adjacency_list[person_name]\n",
    "\n",
    "        headers = find_valid_headers(file_path)\n",
    "        if not headers:\n",
    "            print(f\"⚠️ Warning: No valid headers found in '{filename}', skipping.\")\n",
    "            continue\n",
    "\n",
    "        with open(file_path, newline='', encoding='utf-8-sig', errors='replace') as csvfile:\n",
    "            reader = csv.DictReader(csvfile, fieldnames=headers)\n",
    "            next(reader, None)\n",
    "\n",
    "            for row_num, row in enumerate(reader, start=2):\n",
    "                try:\n",
    "                    first_name = normalize_name(row.get('First Name', ''))\n",
    "                    last_name = normalize_name(row.get('Last Name', ''))\n",
    "                    full_name = f\"{first_name} {last_name}\".strip()\n",
    "\n",
    "                    if full_name:\n",
    "                        adjacency_list[full_name]\n",
    "                        adjacency_list[person_name].add(full_name)\n",
    "                        adjacency_list[full_name].add(person_name)\n",
    "                except Exception as e:\n",
    "                    skipped_rows_log.append(f\"Skipped row {row_num} in '{filename}': {e}\")\n",
    "                    continue\n",
    "\n",
    "    adjacency_list = {k: sorted(list(v)) for k, v in adjacency_list.items()}\n",
    "    return adjacency_list, csv_files, skipped_rows_log\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save JSON Output\n",
    "def save_json(data, file_path):\n",
    "    \"\"\"Save dictionary as a JSON file.\"\"\"\n",
    "    with open(file_path, \"w\", encoding=\"utf-8\") as f:\n",
    "        json.dump(data, f, indent=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      " Cleaned adjacency list saved to cleaned_adjacency_list.json\n",
      "Total nodes in cleaned graph: 28555\n",
      "\n",
      "Summary:\n",
      "Total CSV files found: 126\n",
      "Total students in AllSU list: 158\n",
      "Students who did NOT submit CSV: 30\n",
      "Students who did NOT submit CSV but appear as nodes: 28\n",
      "- aslam khan\n",
      "- avinash kumar\n",
      "- deepak mandal\n",
      "- dilip vaishnav\n",
      "- gaurav bhargava\n",
      "- gaurav kumar\n",
      "- guman singh\n",
      "- harsh chourasiya\n",
      "- hirak nath\n",
      "- jagriti pandey\n",
      "- joel moirangthem\n",
      "- mani kumar\n",
      "- manish chhaba\n",
      "- nikhil mehta\n",
      "- nirmal kumar\n",
      "- pawan kumar\n",
      "- prem kushwaha\n",
      "- rajeev yadav\n",
      "- rakshita biradar\n",
      "- ritesh jha\n",
      "- ritesh yadav\n",
      "- rohit kahar\n",
      "- shalini priya\n",
      "- shreyank sthavaramath\n",
      "- surveer rao\n",
      "- tamnna parveen\n",
      "- vishal yadav\n",
      "- yash yadav\n",
      "\n",
      " Students who did NOT submit CSV and also do NOT appear as nodes: 2\n",
      "- abhilash rayala\n",
      "- shivam sindhu\n"
     ]
    }
   ],
   "source": [
    "# Extract (first, last) from name\n",
    "def get_first_last(name):\n",
    "    words = name.strip().lower().split()\n",
    "    return (words[0], words[-1]) if words else (\"\", \"\")\n",
    "\n",
    "# Run Cleaning Process\n",
    "folder_path = \"LinkedIn Data FILES\"\n",
    "adjacency_list, csv_files, skipped_rows_log = create_adjacency_list(folder_path)\n",
    "\n",
    "if not adjacency_list:\n",
    "    print(\"No connections found.\")\n",
    "else:\n",
    "    output_file = \"cleaned_adjacency_list.json\"  # Save outside the folder\n",
    "    save_json(adjacency_list, output_file)\n",
    "    print(f\"\\n Cleaned adjacency list saved to {output_file}\")\n",
    "    print(f\"Total nodes in cleaned graph: {len(adjacency_list)}\")\n",
    "\n",
    "    # Compare With Master List\n",
    "    student_excel = \"AllSU.csv\"\n",
    "    df_students = pd.read_csv(student_excel)\n",
    "\n",
    "    # Normalize names and extract (first, last)\n",
    "    df_students['Full Name'] = df_students['Full Name'].astype(str).apply(normalize_name)\n",
    "    all_students_full = df_students['Full Name'].tolist()\n",
    "    all_students_first_last = [get_first_last(name) for name in all_students_full]\n",
    "\n",
    "    # Prepare keys\n",
    "    json_nodes = {get_first_last(name) for name in adjacency_list.keys()}\n",
    "    csv_files_first_last = {get_first_last(name) for name in csv_files}\n",
    "\n",
    "    # Find missing sets\n",
    "    missing_all = [name for name in all_students_first_last if name not in csv_files_first_last]\n",
    "    missing_csv_but_in_json = sorted([name for name in missing_all if name in json_nodes])\n",
    "    missing_csv_and_not_in_json = sorted([name for name in missing_all if name not in json_nodes])\n",
    "\n",
    "    # Summary Report\n",
    "    print(f\"\\nSummary:\")\n",
    "    print(f\"Total CSV files found: {len(csv_files)}\")\n",
    "    print(f\"Total students in AllSU list: {len(all_students_first_last)}\")  # fixed this line\n",
    "    print(f\"Students who did NOT submit CSV: {len(missing_all)}\")\n",
    "    print(f\"Students who did NOT submit CSV but appear as nodes: {len(missing_csv_but_in_json)}\")\n",
    "    for first, last in missing_csv_but_in_json:\n",
    "        print(f\"- {first} {last}\")\n",
    "    print(f\"\\n Students who did NOT submit CSV and also do NOT appear as nodes: {len(missing_csv_and_not_in_json)}\")\n",
    "    for first, last in missing_csv_and_not_in_json[:5]:\n",
    "        print(f\"- {first} {last}\")\n",
    "\n",
    "# Show Skipped Rows\n",
    "if skipped_rows_log:\n",
    "    print(\"\\n--- Skipped Rows Log ---\")\n",
    "    for log in skipped_rows_log:\n",
    "        print(log)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "myenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
